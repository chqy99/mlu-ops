/*************************************************************************
 * Copyright (C) [2023] by Cambricon, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include "dot_product.h"
#include "kernels/kernel.h"

#ifndef PAD_DOWN
#define PAD_DOWN(x, y) (((x) / (y)) * (y))
#endif

#ifndef PAD_UP
#define PAD_UP(x, y) (((x) / (y) + (int)((x) % (y) > 0)) * (y))
#endif

// 先用一个origin_ram申请一块足够大的片上空间
// 后续算子所需的各个具体空间的初始化可以通过各自加偏移值来实现
__nram__ char nram_buffer[MAX_NRAM_SIZE];

__mlu_func__ void compute(const float *x,
                          const float *y,
                          const int32_t n,
                          float *output) {
  // 此处将nram划分为两块空间nram_x、nram_y、out_buffer，分别用于存放x、y、输出的缓存
  // 由于计算指令需要对齐到128B，此处num_deal表示nram_x一次能存放多少个对齐后的数据
  const int32_t NRAM_X_Y_SIZE = MAX_NRAM_SIZE - 2 * NFU_ALIGN_SIZE;
  const int32_t num_float_align = NFU_ALIGN_SIZE / sizeof(float);
  const int32_t num_deal = PAD_DOWN(NRAM_X_Y_SIZE / 2 / sizeof(float),
                                    num_float_align);
  const int32_t num_deal_align = num_deal / num_float_align;
  char *nram_x = nram_buffer;
  char *nram_y = nram_buffer + NRAM_X_Y_SIZE / 2;
  char *out_buffer = nram_buffer + NRAM_X_Y_SIZE;
  // 输出缓冲值赋0
  *(float *)out_buffer = 0.0;

  // 当前core需要处理的数据量为n，此处计算需重复处理的次数
  const int32_t repeat = n / num_deal;
  const int32_t remin = n % num_deal;

  // 循环处理部分
  for (int32_t i = 0; i < repeat; ++i) {
    // load
    __memcpy_async(nram_x, x + i * num_deal, num_deal * sizeof(float),
                   GDRAM2NRAM);
    __memcpy_async(nram_y, y + i * num_deal, num_deal * sizeof(float),
                   GDRAM2NRAM);
    // __asm__ volatile("sync;\n\t"); 对齐_async指令
    __sync();
    // compute
    __bang_mul((float *)nram_y, (float *)nram_y, (float *)nram_x, num_deal);

    // 将值累加到第一位
    // nram_x、nram_y相当于存储了1×num_deal_align×32个float型数据
    // sumpool指定宽、高，kernel只需要处理第一列，步进设为数据尺寸
    __bang_sumpool((float *)nram_x, (float *)nram_y, 1, num_deal_align,
                   num_float_align, num_deal_align, 1, num_deal_align, 1);
    // __bang_reduce_sum按128字节求和放置首位
    __bang_reduce_sum((float *)nram_y, (float *)nram_x, num_float_align);
    // 加到缓冲区
    __bang_add((float *)out_buffer, (float *)nram_y, (float *)out_buffer, 1);
    __sync();
  }

  // 处理余数部分
  if (remin > 0) {
    __memcpy_async(nram_x, x + repeat * num_deal,
                   remin * sizeof(float), GDRAM2NRAM);
    __memcpy_async(nram_y, y + repeat * num_deal,
                   remin * sizeof(float), GDRAM2NRAM);
    // remin以128字节向上取整
    const int32_t remin_align = PAD_UP(remin, num_float_align);
    // 如果remin * sizeof(float)不是128的倍数，则需要处理尾数,通过补0处理
    if (remin_align > remin) {
      float pad = 0.0;
      __memset_nram_async((float *)nram_x + remin, remin_align - remin, pad);
      __memset_nram_async((float *)nram_y + remin, remin_align - remin, pad);
    }
    __sync();

    // compute
    __bang_mul((float *)nram_y, (float *)nram_y, (float *)nram_x, remin_align);

    // 将值累加到第一位
    // nram_x、nram_y相当于存储了1×remin_align个float型数据
    // sumpool指定宽、高，kernel只需要处理第一列，步进设为数据尺寸
    const int32_t num_remin_align = remin_align / num_float_align;
    __bang_sumpool((float *)nram_x, (float *)nram_y, 1, num_remin_align,
                   num_float_align, num_remin_align, 1, num_remin_align, 1);
    // __bang_reduce_sum按128字节求和放置首位
    __bang_reduce_sum((float *)nram_y, (float *)nram_x, num_float_align);
    // 加到缓冲区
    __bang_add((float *)out_buffer, (float *)nram_y, (float *)out_buffer, 1);
    __sync();
  }
}

// kernel入口函数
__mlu_global__ void MLUKernelDotProduct(const float *x,
                                        const float *y,
                                        const int32_t element_num,
                                        float *output) {
  /* 在每个core运行时，我们可以通过taskDim和taskId获取有关多核的信息。
      - taskDim可以表示执行该算子时触发的core总数
      - taskId可以表示执行时这个core对应的序号，taskId ∈[0, taskDim - 1]
      
      有了这两个信息，
      我们便可以计算出每个core需要处理的数据大小、每个core对输入输出空间
      访存时加的偏移各是多少等等。实际的拆分策略还是需要根据算子实际情况
      来考虑。比如有的算子得在最高维度拆分，有的算子只需对所有数据平均拆分。 */

  // 平均每个核要处理的数据
  const int32_t n_seg = element_num / taskDim + (taskId == taskDim - 1)
                       * (element_num % taskDim);

  // 每个core要对不同的数据区域做处理，所以需要根据taskId加偏移
  const float *x_offset = x + element_num / taskDim * taskId;
  const float *y_offset = y + element_num / taskDim * taskId;

  // 调用实现函数
  compute(x_offset, y_offset, n_seg, output);
}
